{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d714935",
   "metadata": {},
   "source": [
    "![alt text](<data/logoET.png>)\n",
    "\n",
    "# ET in Italia: Scienza e Tecnologia\n",
    "Assisi, 20-23 February 2024\n",
    "\n",
    "\n",
    "## GWFish Tutorial\n",
    "This is a brief tutorial on how to use GWFish software, which is publicly available on [GitHub](https://github.com/janosch314/GWFish). For convenience, we are going to work on Google Colab, but there are a few lineguides to run this tutorial on your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26857820",
   "metadata": {},
   "source": [
    "### Settings for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q git+https://github.com/janosch314/GWFish.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f8f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q lalsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d391910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q corner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea308832",
   "metadata": {},
   "source": [
    "**Note 1**: in Google Colab remember to **restart the kernel runtime** after installation: `runtime -> restart session`\n",
    "\n",
    "**Note 2**: GWFish uses LALSimulation, so the package needs to be installed separately from GWFish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73abd866",
   "metadata": {},
   "source": [
    "### On your PC\n",
    "To make GWFish modules available from any location in your PC, after clonig the repository\n",
    "```\n",
    "git clone git@github.com:janosch314/GWFish.git\n",
    "```\n",
    "execute the command\n",
    "```\n",
    "pip install .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6552bc",
   "metadata": {},
   "source": [
    "# Let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f55fa3d",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0690618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GWFish.modules as gw\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import corner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from astropy.cosmology import Planck18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7d4f7f",
   "metadata": {},
   "source": [
    "## GWFish in 2 functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb65c6",
   "metadata": {},
   "source": [
    "GWfish allows for 2 main functions for ordinary analysis:\n",
    "- ```compute_network_errors```\n",
    "- ```analyze_and_save_to_txt```\n",
    "\n",
    "The output is the same, but the second function allows to save it in a folder chosen by the user.\n",
    "\n",
    "We will now give all the usage details for both functions using one event only, inspired to GW170817."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a125b68",
   "metadata": {},
   "source": [
    "## Single Event Analysis: GW170817-like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9eb25c",
   "metadata": {},
   "source": [
    "### Initialize GWFish\n",
    "\n",
    "Here we are using the **GW180817** BNS event as it would have been seen with a triangular-shape ET located in Sardinia.\n",
    "\n",
    "1. We need to specify the network: list of detectors that work together (all the detectors characteristics are specified in the **detectors.yaml** file)\n",
    "2. Parameters describing the event we want to analyze as a DataFrame\n",
    "3. Parameters entering in the Fisher matrix\n",
    "4. The choice of the waveform approximant can be done from all the availbale waveforms from **LALSimulation** (the default waveform class is in frequency domain)\n",
    "5. For a more realistic analysis we can include the **duty cycle** of the detectors using `use_duty_cycle = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f171d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The detector names can be accessed in detectors.yaml file\n",
    "# One can list as many detectors as they want: ['H1', 'L1', 'V1', 'CE', 'ET']\n",
    "detectors = ['ET']\n",
    "# The networks are the combinations of detectors that will be used for the analysis\n",
    "# The detection_SNR is the minimum SNR for a detection:\n",
    "#   --> The first entry specifies the minimum SNR for a detection in a single detector\n",
    "#   --> The second entry specifies the minimum network SNR for a detection\n",
    "network = gw.detection.Network(detector_ids = detectors, detection_SNR = (0., 8.))\n",
    "\n",
    "# We choose a waveform approximant suitable for BNS analysis\n",
    "# In this case we are taking into account tidal polarizability effects\n",
    "waveform_model = 'IMRPhenomD_NRTidalv2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377cbee",
   "metadata": {},
   "source": [
    "**Injections**\n",
    "\n",
    "As said before, one can analyze single events or entire populations (see below). Here consider the GW170817 event. \n",
    "\n",
    "The parameters need to passed as a **DataFrame** with the following nomenclature:\n",
    "- `mass_1`: primary mass of the binary in [Msol] (in source frame)\n",
    "- `mass_2`: secondary mass of the binary in [Msol] (in source frame)\n",
    "- `redshift`: the redshift of the merger\n",
    "- `luminosity_distance`:  the luminosity distance of the merger in [Mpc], usually one sets the redshift and calculates the corresponding luminosity distance using Planck18 cosmology (see below)\n",
    "- `theta_jn`: the inclination angle between the line of observation and the perpendicular to the binary plane in [rad]\n",
    "- `dec`: declination angle in [rad]\n",
    "- `ra`: right ascension in [rad]\n",
    "- `psi`: the polarization angle in [rad]\n",
    "- `phase`: the initial phase of the merger in [rad]\n",
    "- `geocent_time`: merger time as GPS time in [s]\n",
    "- `a_1`: dimensionless spin parameter of primary component\n",
    "- `a_2`: dimensionless spin parameter of secondary component\n",
    "- `tilt_1`: zenith angle between the spin and orbital angular momenta for the primary component in [rad]\n",
    "- `tilt_2`: zenith angle between the spin and orbital angular momenta for the secondary component in [rad]\n",
    "- `phi_12`: difference between total and orbital angular momentum azimuthal angles in [rad]\n",
    "- `phi_jl`: difference between the azimuthal angles of the individual spin vector projections on to the orbital plane in [rad]\n",
    "- `lambda_1`: dimensionless tidal polarizabilty of primary component\n",
    "- `lambda_2`: dimensionless tidal polarizabilty of secondary component\n",
    "\n",
    "The `lambda_1` and `lambda_2` parameters are for neutron stars only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5153023",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([0.00980])\n",
    "\n",
    "parameters = {\n",
    "    'mass_1': np.array([1.4957673]), \n",
    "    'mass_2': np.array([1.24276395]), \n",
    "    'redshift': z,\n",
    "    'luminosity_distance': Planck18.luminosity_distance(z).value,\n",
    "    'theta_jn': np.array([2.545065595974997]),\n",
    "    'ra': np.array([3.4461599999999994]),\n",
    "    'dec': np.array([-0.4080839999999999]),\n",
    "    'psi': np.array([0.]),\n",
    "    'phase': np.array([0.]),\n",
    "    'geocent_time': np.array([1187008882.4]),\n",
    "    'a_1':np.array([0.005136138323169717]), \n",
    "    'a_2':np.array([0.003235146993487445]), \n",
    "    'lambda_1':np.array([368.17802383555687]), \n",
    "    'lambda_2':np.array([586.5487031450857])}\n",
    "parameters = pd.DataFrame(parameters)\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f560ce76",
   "metadata": {},
   "source": [
    "### Initialize Network\n",
    "\n",
    "If we want to compute the Fisher matrix we need to specify the parameters in the detector network settigs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b40344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fisher parameters are the parameters that will be used to calculate the Fisher matrix\n",
    "# and on which we will calculate the errors\n",
    "fisher_parameters = ['mass_1', 'mass_2', 'luminosity_distance', 'theta_jn', 'dec','ra',\n",
    "                     'psi', 'phase', 'geocent_time', 'a_1', 'a_2', 'lambda_1', 'lambda_2']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9bd0b5",
   "metadata": {},
   "source": [
    "### Calculate SNR and Errors for 1 event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fddc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_snr, parameter_errors, sky_localization = gw.fishermatrix.compute_network_errors(\n",
    "        network = network,\n",
    "        parameter_values = parameters,\n",
    "        fisher_parameters=fisher_parameters, \n",
    "        waveform_model = waveform_model\n",
    "        )   \n",
    "        # use_duty_cycle = False, # default is False anyway\n",
    "        # save_matrices = False, # default is False anyway\n",
    "        # save_matrices_path = None, # default is None anyway, otherwise specify the folder where to save the Fisher and corresponding covariance matrices\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e52934",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The network SNR of the event is ', network_snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa8b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The sky localization of the event is ', sky_localization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose percentile factor of sky localization and pass from rad2 to deg2\n",
    "percentile = 90.\n",
    "sky_localization_90cl = sky_localization * gw.fishermatrix.sky_localization_percentile_factor(percentile)\n",
    "sky_localization_90cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One can create a dictionary with the parameter errors, the order is the same as the one given in fisher_parameters\n",
    "parameter_errors_dict = {}\n",
    "for i, parameter in enumerate(fisher_parameters):\n",
    "    parameter_errors_dict['err_' + parameter] = np.squeeze(parameter_errors)[i]\n",
    "\n",
    "print('The parameter errors of the event are ')\n",
    "parameter_errors_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fec3ec",
   "metadata": {},
   "source": [
    "### Some more advanced GWFish usage: Plot Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56e833",
   "metadata": {},
   "source": [
    "Since no function gives you directly the signal one has to enter into the details of what is internally done in the ```compute_network_errors``` function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce958beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The waveform model can be accessed through the waveform_class attribute,\n",
    "# which requires the waveform_model and the data_params and the parameters of the event\n",
    "waveform_class = gw.waveforms.LALFD_Waveform\n",
    "data_params = {\n",
    "        'frequencyvector': network.detectors[0].frequencyvector,\n",
    "        'f_ref': 50.\n",
    "    }\n",
    "waveform_obj = waveform_class(waveform_model, parameters.iloc[0], data_params)\n",
    "wave = waveform_obj()\n",
    "t_of_f = waveform_obj.t_of_f\n",
    "\n",
    "# The waveform is then projected onto the detector taking into account the Earth rotation \n",
    "# by passing at each frequency step the time of the waveform at the detector\n",
    "signal = gw.detection.projection(parameters.iloc[0], network.detectors[0], wave, t_of_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The projected amplitude is stored in the signal variable\n",
    "# We have 3 columns as ET is made of 3 detectors\n",
    "signal1, signal2, signal3 = signal[:, 0], signal[:, 1], signal[:, 2]\n",
    "signal_ampl = np.sqrt(np.abs(signal1)**2. + np.abs(signal2)**2. + np.abs(signal3)**2.)\n",
    "\n",
    "# The PSD of the ET-D detector is stored in the detector_psd folder\n",
    "# We need to specify the path to the file\n",
    "GWFish_path = '/usr/local/lib/python3.10/dist-packages/GWFish/' # path on Colab (check for right path on your PC!)\n",
    "psd_et_D = np.loadtxt(os.path.join(GWFish_path,'detector_psd/ET_psd.txt'), usecols=[0,1])\n",
    "frequencyvector = network.detectors[0].frequencyvector[:, 0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "ax.plot(frequencyvector, 2. * np.sqrt(frequencyvector) * signal_ampl, \n",
    "        linewidth=2., label='%s' %(waveform_model))\n",
    "ax.plot(psd_et_D[:,0], np.sqrt(psd_et_D[:,0]) * np.sqrt(psd_et_D[:,1]), linewidth = 2.0, color = 'C2', label = 'ET-D ASD')\n",
    "\n",
    "ax.set_xlim(1.,frequencyvector[-1])\n",
    "ax.set_ylim(1e-24, 1e-20)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('f [Hz]', fontsize=15)\n",
    "ax.set_ylabel(r'Characteristic strain', fontsize=15)\n",
    "plt.grid(linestyle='dotted', linewidth='0.6', which='both')\n",
    "ax.legend(loc='upper right', fontsize=15, ncol=1, fancybox=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a93c8e7",
   "metadata": {},
   "source": [
    "### A note on characteristic strain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37bea2c",
   "metadata": {},
   "source": [
    "The characteristic strain is a particular combination of signal/ASD with frequency so that the output is adimensional and the area in between the signal and the detector's densitivity curve can be interpreted as SNR:\n",
    "\n",
    "$$\n",
    "SNR^2 = 4\\int\\frac{h(f)h^*(f)}{S_n}df\n",
    "$$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\n",
    "h_c = 2f|h| \\quad \\text{and} \\quad S_n = \\sqrt{f}\\sqrt{PSD}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0096a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time before merger as a function of frequency\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "conv_to_hours = 3600\n",
    "ax.plot(frequencyvector, (t_of_f - parameters['geocent_time'].iloc[0]) / conv_to_hours, linewidth = 2.)\n",
    "\n",
    "ax.set_xlim(1.,frequencyvector[-1])\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('f [Hz]', fontsize = 15)\n",
    "ax.set_ylabel(r'time before merger [hours]', fontsize=15)\n",
    "plt.grid(linestyle = 'dotted', linewidth = '0.6', which = 'both')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b69f52",
   "metadata": {},
   "source": [
    "### The ```analyze_and_save_to_txt``` function: save results to file and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir gwfish_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78310953",
   "metadata": {},
   "source": [
    "The difference with respect to the ```compute_network_errors``` function is that one can pass different network combinations and get results files for each of them. This means that if your detectors list is something like ```['LHO', 'LLO', 'VIR', 'CE1', 'ET']``` and you want to create 3 different networks out of it, i.e. ```['LHO', 'LLO', 'VIR']```, ```['CE1', 'ET']``` and ```['ET']``` alone, then one should inizialize the ```analyze_and_save_to_txt``` function as follows:\n",
    "\n",
    "```\n",
    "network = gw.detection.Network(detector_ids = ['LHO', 'LLO', 'VIR', 'CE1', 'ET'], detection_SNR = (0., 8.))\n",
    "```\n",
    "\n",
    "and then specify the different network combinations:\n",
    "\n",
    "```\n",
    "sub_network_ids_list = [[0, 1, 2], [3, 4], [4]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0079fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'gwfish_results'\n",
    "network = gw.detection.Network(detector_ids = ['ET'], detection_SNR = (0., 8.))\n",
    "gw.fishermatrix.analyze_and_save_to_txt(network = network,\n",
    "                                        parameter_values  = parameters,\n",
    "                                        fisher_parameters = fisher_parameters, \n",
    "                                        sub_network_ids_list = [[0]],\n",
    "                                        population_name = 'BNS',\n",
    "                                        waveform_model = waveform_model,\n",
    "                                        save_path = data_folder,\n",
    "                                        save_matrices = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d20cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_matrix = np.load(data_folder + '/' + 'fisher_matrices_ET_BNS_SNR8.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76199ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = pd.read_csv(data_folder + '/' + 'Errors_ET_BNS_SNR8.txt', delimiter = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c893e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One can access all the column names of the errors output file:\n",
    "errors.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92437238",
   "metadata": {},
   "source": [
    "Same errors as before just save to a .txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e60a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4deb1f",
   "metadata": {},
   "source": [
    "### A quick test\n",
    "\n",
    "One would expect that the Fisher matrix entry corresponding to dL-dL should be approximated by the ratio between the SNR and the luminosity distance squared as follows:\n",
    "\n",
    "$$\n",
    "\\frac{1}{SNR} = \\frac{\\Delta d_L}{d_L}\n",
    "$$\n",
    "\n",
    "where $\\Delta d_L = \\left[F\\right]^{-1}_{d_L,d_L}$.\n",
    "\n",
    "A rough approximation in literature takes: $\\frac{\\Delta d_L}{d_L} \\sim \\frac{2}{SNR}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd293a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_fisher = fisher_matrix[0, :, :]\n",
    "print('We expect Delta dL/dL to scale as 1/SNR')\n",
    "print('fisher matrix dL-dL: ', my_fisher[2, 2])\n",
    "print('(SNR/dL)^2: ', (errors['network_SNR'].iloc[0] / errors['luminosity_distance'].iloc[0])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afa2238",
   "metadata": {},
   "source": [
    "### Corner plot\n",
    "\n",
    "Using the covariance matrix one show all the correlations between pairs of parameters in a corner plot. Using as inputs the injected values and the covariance matrix, one samples from a multivariate Gaussian distribution and plot the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f83509",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORNER_KWARGS = dict(\n",
    "    bins = 50, # number of bins for histograms\n",
    "    smooth = 0.99, # smooths out contours. \n",
    "    plot_datapoints = True, # choose if you want datapoints\n",
    "    label_kwargs = dict(fontsize = 12), # font size for labels\n",
    "    show_titles = True, #choose if you want titles on top of densities.\n",
    "    title_kwargs = dict(fontsize = 12), # font size for title\n",
    "    plot_density = False,\n",
    "    title_quantiles = [0.16, 0.5, 0.84],  # add quantiles to plot densities for 1d hist\n",
    "    levels = (1 - np.exp(-0.5), 1 - np.exp(-2), 1 - np.exp(-9 / 2.)), # 1, 2 and 3 sigma contours for 2d plots\n",
    "    fill_contours = True, #decide if you want to fill the contours\n",
    "    max_n_ticks = 2, # set a limit to ticks in the x-y axes.\n",
    "    title_fmt=\".3f\"\n",
    "    )\n",
    "corner_lbs = [r'$m_1$ $[M_{\\odot}]$', '$m_2$ $[M_{\\odot}]$', '$D_l$ [Mpc]',\n",
    "                '$\\iota$ [rad]', '$DEC$ [rad]', '$RA$ [rad]', '$\\Psi$ [rad]',\n",
    "                 '$phase$', '$t_c$', '$a_1$', '$a_2$', '$\\Lambda_1$', '$\\Lambda_2$']\n",
    "\n",
    "mean_lbs = ['mass_1', 'mass_2', 'luminosity_distance', 'theta_jn', 'dec', 'ra', 'psi',\n",
    "            'phase', 'geocent_time', 'a_1', 'a_2', 'lambda_1', 'lambda_2']\n",
    "mean_values = parameters[mean_lbs].iloc[0] # mean values of the parameters\n",
    "cov_matrix = np.load(data_folder + '/' + 'inv_fisher_matrices_ET_BNS_SNR8.npy')[0, :, :]\n",
    "\n",
    "# Sample from a multi-variate gaussian with the given covariance matrix and injected mean values\n",
    "samples = np.random.multivariate_normal(mean_values, cov_matrix, int(1e6))\n",
    "fig = corner.corner(samples, labels = corner_lbs, truths = mean_values, truth_color = 'red',\n",
    "                    **CORNER_KWARGS)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74e68f7",
   "metadata": {},
   "source": [
    "## Some exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc698469",
   "metadata": {},
   "source": [
    "### 1. Compare waveforms\n",
    "Take the GW170817-like event we have analyzed so far and try to compare the error estimate using two different waveforms (for example the basic TaylorF2 and the IMRPhenomHM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043ecf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473062f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd147e75",
   "metadata": {},
   "source": [
    "### 2. Compare networks\n",
    "Take our GW17817-like event and compare results using ET alone and the O5-like network composed of LIGO-Hanford (LHO), LIGO Livingston (LLO), Virgo (VIR) and KAGRA (KAG). What happens to sky localization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128a23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f2a72e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d51feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6237c32a",
   "metadata": {},
   "source": [
    "### A quick note on detectors setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a7419",
   "metadata": {},
   "source": [
    "Detectors are all described in the ```.yaml``` file. The general settings are as follows (in case you want to customize your own detector):\n",
    "\n",
    "```\n",
    "ET: # name label of the detector\n",
    "            lat:              (40 + 31. / 60 ) * np.pi / 180.\n",
    "            lon:              (9 + 25. / 60) * np.pi / 180.\n",
    "            opening_angle:    np.pi / 3.\n",
    "            azimuth:          70.5674 * np.pi / 180.\n",
    "            psd_data:         ET_psd.txt # file containg two columns: frequency, psd\n",
    "            duty_factor:      0.85\n",
    "            detector_class:   earthDelta # for triangle-shaped detector or earthL if usual-shape detector\n",
    "            plotrange:        3, 1000, 1e-25, 1e-20\n",
    "            fmin:             2. # minimum frequency of the detector\n",
    "            fmax:             2048. # maximum frequency of the detector\n",
    "            spacing:          geometric\n",
    "            df:               1./16.\n",
    "            npoints:          1000\n",
    "```\n",
    "\n",
    "The ```spacing``` variable can either be ```geometric``` (logarithmic spacing of the frequency vector for waveform evaluation with a number of points specified by the ```npoints``` variable, faster solution) or ```linear``` (linear spacing of the frequency vector to evaluate the waveform with spacing given by ```df```, slower solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae3d028",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
